{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "# import re\n",
    "# import threading\n",
    "# from multiprocessing import Pool\n",
    "import os\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Sets the random seed for Python, NumPy, and PyTorch to ensure reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # If using a GPU (CUDA backend), ensure deterministic behavior if needed\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Usage\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<h1>Dataset:<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_patient_data_csv = \"../../synthea/silver/updated_patient_data.csv\"\n",
    "\n",
    "path_providers_data_csv = \"../../synthea/providers.csv\"\n",
    "\n",
    "temp_train_df = pd.read_csv(path_patient_data_csv)\n",
    "\n",
    "kktemp_train_df = temp_train_df.drop([\"SPECIALITY\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(path_patient_data_csv)\n",
    "# tmp = tmp[\"SPECIALITY\"]\n",
    "\n",
    "# Select the 'SPECIALITY' column and drop duplicates\n",
    "unique_specialities = tmp[\"condition\"].drop_duplicates()\n",
    "\n",
    "# Save the unique specialities to a new CSV file\n",
    "unique_specialities.to_csv(\"unique_conditions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_train_df[[\"condition\", \"SPECIALTY\"]]\n",
    "temp.to_csv(\"temp.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8395\n"
     ]
    }
   ],
   "source": [
    "print(len(temp_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>BIRTHDATE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>condition_start</th>\n",
       "      <th>condition_stop</th>\n",
       "      <th>encounter</th>\n",
       "      <th>condition</th>\n",
       "      <th>encounter_type</th>\n",
       "      <th>reason_id</th>\n",
       "      <th>reason</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>SPECIALTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>1989-05-25</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>575 BEECH STREET</td>\n",
       "      <td>HOLYOKE</td>\n",
       "      <td>MA</td>\n",
       "      <td>Hampden County</td>\n",
       "      <td>01040</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>4e595f0c-f50f-461b-a04e-13b4e492350e</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>Encounter for symptom</td>\n",
       "      <td>444814009.0</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>1989-05-25</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>575 BEECH STREET</td>\n",
       "      <td>HOLYOKE</td>\n",
       "      <td>MA</td>\n",
       "      <td>Hampden County</td>\n",
       "      <td>01040</td>\n",
       "      <td>2011-12-08</td>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>792fae81-a007-44b0-8221-46953737b089</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>Encounter for symptom</td>\n",
       "      <td>444814009.0</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>1989-05-25</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>575 BEECH STREET</td>\n",
       "      <td>HOLYOKE</td>\n",
       "      <td>MA</td>\n",
       "      <td>Hampden County</td>\n",
       "      <td>01040</td>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8f104aa7-4ca9-4473-885a-bba2437df588</td>\n",
       "      <td>Chronic sinusitis (disorder)</td>\n",
       "      <td>Encounter for symptom</td>\n",
       "      <td>36971009.0</td>\n",
       "      <td>Sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
       "      <td>1983-11-14</td>\n",
       "      <td>F</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>1493 CAMBRIDGE STREET</td>\n",
       "      <td>CAMBRIDGE</td>\n",
       "      <td>MA</td>\n",
       "      <td>Middlesex County</td>\n",
       "      <td>02138</td>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>3b639086-5fbc-4720-8c31-e8c8c0f1d660</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>Encounter for symptom</td>\n",
       "      <td>10509002.0</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>e6283e46-fd81-3611-9459-0edb1c3da357</td>\n",
       "      <td>Pulmonologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10339b10-3cd1-4ac3-ac13-ec26728cb592</td>\n",
       "      <td>1992-06-02</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>575 BEECH STREET</td>\n",
       "      <td>HOLYOKE</td>\n",
       "      <td>MA</td>\n",
       "      <td>Hampden County</td>\n",
       "      <td>01040</td>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>27ff7518-6d93-4308-8a1d-d2dfb02c0c58</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>Encounter for symptom</td>\n",
       "      <td>10509002.0</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Pulmonologist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             patient_id   BIRTHDATE GENDER   RACE  \\\n",
       "0  1d604da9-9a81-4ba9-80c2-de3375d59b40  1989-05-25      M  white   \n",
       "1  1d604da9-9a81-4ba9-80c2-de3375d59b40  1989-05-25      M  white   \n",
       "2  1d604da9-9a81-4ba9-80c2-de3375d59b40  1989-05-25      M  white   \n",
       "3  034e9e3b-2def-4559-bb2a-7850888ae060  1983-11-14      F  white   \n",
       "4  10339b10-3cd1-4ac3-ac13-ec26728cb592  1992-06-02      M  white   \n",
       "\n",
       "     ETHNICITY                ADDRESS       CITY STATE            COUNTY  \\\n",
       "0     hispanic       575 BEECH STREET    HOLYOKE    MA    Hampden County   \n",
       "1     hispanic       575 BEECH STREET    HOLYOKE    MA    Hampden County   \n",
       "2     hispanic       575 BEECH STREET    HOLYOKE    MA    Hampden County   \n",
       "3  nonhispanic  1493 CAMBRIDGE STREET  CAMBRIDGE    MA  Middlesex County   \n",
       "4  nonhispanic       575 BEECH STREET    HOLYOKE    MA    Hampden County   \n",
       "\n",
       "     ZIP condition_start condition_stop                             encounter  \\\n",
       "0  01040      2019-03-20     2019-04-10  4e595f0c-f50f-461b-a04e-13b4e492350e   \n",
       "1  01040      2011-12-08     2011-12-22  792fae81-a007-44b0-8221-46953737b089   \n",
       "2  01040      2001-05-01            NaN  8f104aa7-4ca9-4473-885a-bba2437df588   \n",
       "3  02138      2016-12-29     2017-01-05  3b639086-5fbc-4720-8c31-e8c8c0f1d660   \n",
       "4  01040      2019-04-23     2019-05-07  27ff7518-6d93-4308-8a1d-d2dfb02c0c58   \n",
       "\n",
       "                      condition         encounter_type    reason_id  \\\n",
       "0    Viral sinusitis (disorder)  Encounter for symptom  444814009.0   \n",
       "1    Viral sinusitis (disorder)  Encounter for symptom  444814009.0   \n",
       "2  Chronic sinusitis (disorder)  Encounter for symptom   36971009.0   \n",
       "3   Acute bronchitis (disorder)  Encounter for symptom   10509002.0   \n",
       "4   Acute bronchitis (disorder)  Encounter for symptom   10509002.0   \n",
       "\n",
       "                        reason                           provider_id  \\\n",
       "0   Viral sinusitis (disorder)  af01a385-31d3-3c77-8fdb-2867fe88df2f   \n",
       "1   Viral sinusitis (disorder)  af01a385-31d3-3c77-8fdb-2867fe88df2f   \n",
       "2         Sinusitis (disorder)  af01a385-31d3-3c77-8fdb-2867fe88df2f   \n",
       "3  Acute bronchitis (disorder)  e6283e46-fd81-3611-9459-0edb1c3da357   \n",
       "4  Acute bronchitis (disorder)  af01a385-31d3-3c77-8fdb-2867fe88df2f   \n",
       "\n",
       "          SPECIALTY  \n",
       "0  Otolaryngologist  \n",
       "1  Otolaryngologist  \n",
       "2  Otolaryngologist  \n",
       "3     Pulmonologist  \n",
       "4     Pulmonologist  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>condition</th>\n",
       "      <th>reason</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>SPECIALTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Chronic sinusitis (disorder)</td>\n",
       "      <td>Sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
       "      <td>F</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>e6283e46-fd81-3611-9459-0edb1c3da357</td>\n",
       "      <td>Pulmonologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10339b10-3cd1-4ac3-ac13-ec26728cb592</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Pulmonologist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             patient_id GENDER   RACE    ETHNICITY  \\\n",
       "0  1d604da9-9a81-4ba9-80c2-de3375d59b40      M  white     hispanic   \n",
       "1  1d604da9-9a81-4ba9-80c2-de3375d59b40      M  white     hispanic   \n",
       "2  1d604da9-9a81-4ba9-80c2-de3375d59b40      M  white     hispanic   \n",
       "3  034e9e3b-2def-4559-bb2a-7850888ae060      F  white  nonhispanic   \n",
       "4  10339b10-3cd1-4ac3-ac13-ec26728cb592      M  white  nonhispanic   \n",
       "\n",
       "                      condition                       reason  \\\n",
       "0    Viral sinusitis (disorder)   Viral sinusitis (disorder)   \n",
       "1    Viral sinusitis (disorder)   Viral sinusitis (disorder)   \n",
       "2  Chronic sinusitis (disorder)         Sinusitis (disorder)   \n",
       "3   Acute bronchitis (disorder)  Acute bronchitis (disorder)   \n",
       "4   Acute bronchitis (disorder)  Acute bronchitis (disorder)   \n",
       "\n",
       "                            provider_id         SPECIALTY  \n",
       "0  af01a385-31d3-3c77-8fdb-2867fe88df2f  Otolaryngologist  \n",
       "1  af01a385-31d3-3c77-8fdb-2867fe88df2f  Otolaryngologist  \n",
       "2  af01a385-31d3-3c77-8fdb-2867fe88df2f  Otolaryngologist  \n",
       "3  e6283e46-fd81-3611-9459-0edb1c3da357     Pulmonologist  \n",
       "4  af01a385-31d3-3c77-8fdb-2867fe88df2f     Pulmonologist  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_df = temp_train_df.drop(columns=[\"BIRTHDATE\", \"ADDRESS\", \"CITY\", \"STATE\", \"COUNTY\", \"ZIP\", \"condition_start\", \"condition_stop\", \"encounter\", \"encounter_type\", \"reason_id\"], axis = 1)\n",
    "temp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_train_df = pd.get_dummies(temp_train_df, columns = [\"patient_id\"])\n",
    "# temp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECIALTY\n",
      "Addiction Specialist            21\n",
      "Allergist                       94\n",
      "Burn Specialist                 39\n",
      "Cardiologist                   800\n",
      "Dentist                         57\n",
      "Dermatologist                   25\n",
      "Endocrinologist               1054\n",
      "Gastroenterologist             113\n",
      "General Surgeon                259\n",
      "Hematologist                   300\n",
      "Nephrologist                    85\n",
      "Neurologist                    366\n",
      "Obstetrician                   889\n",
      "Oncologist                      75\n",
      "Ophthalmologist                 22\n",
      "Orthopedic Specialist          542\n",
      "Otolaryngologist              2625\n",
      "Pain Management Specialist      55\n",
      "Plastic Surgeon                 36\n",
      "Psychiatrist                    25\n",
      "Pulmonologist                  634\n",
      "Rheumatologist                   9\n",
      "Toxicologist                    52\n",
      "Trauma Surgeon                   9\n",
      "Urologist                      148\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = temp_train_df.groupby('SPECIALTY').size()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count = temp_train_df[\"patient_id\"].unique()\n",
    "len(unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>condition</th>\n",
       "      <th>reason</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>SPECIALTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>Viral sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Chronic sinusitis (disorder)</td>\n",
       "      <td>Sinusitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Otolaryngologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
       "      <td>F</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>e6283e46-fd81-3611-9459-0edb1c3da357</td>\n",
       "      <td>Pulmonologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10339b10-3cd1-4ac3-ac13-ec26728cb592</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>Acute bronchitis (disorder)</td>\n",
       "      <td>af01a385-31d3-3c77-8fdb-2867fe88df2f</td>\n",
       "      <td>Pulmonologist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             patient_id GENDER   RACE    ETHNICITY  \\\n",
       "0  1d604da9-9a81-4ba9-80c2-de3375d59b40      M  white     hispanic   \n",
       "1  1d604da9-9a81-4ba9-80c2-de3375d59b40      M  white     hispanic   \n",
       "2  1d604da9-9a81-4ba9-80c2-de3375d59b40      M  white     hispanic   \n",
       "3  034e9e3b-2def-4559-bb2a-7850888ae060      F  white  nonhispanic   \n",
       "4  10339b10-3cd1-4ac3-ac13-ec26728cb592      M  white  nonhispanic   \n",
       "\n",
       "                      condition                       reason  \\\n",
       "0    Viral sinusitis (disorder)   Viral sinusitis (disorder)   \n",
       "1    Viral sinusitis (disorder)   Viral sinusitis (disorder)   \n",
       "2  Chronic sinusitis (disorder)         Sinusitis (disorder)   \n",
       "3   Acute bronchitis (disorder)  Acute bronchitis (disorder)   \n",
       "4   Acute bronchitis (disorder)  Acute bronchitis (disorder)   \n",
       "\n",
       "                            provider_id         SPECIALTY  \n",
       "0  af01a385-31d3-3c77-8fdb-2867fe88df2f  Otolaryngologist  \n",
       "1  af01a385-31d3-3c77-8fdb-2867fe88df2f  Otolaryngologist  \n",
       "2  af01a385-31d3-3c77-8fdb-2867fe88df2f  Otolaryngologist  \n",
       "3  e6283e46-fd81-3611-9459-0edb1c3da357     Pulmonologist  \n",
       "4  af01a385-31d3-3c77-8fdb-2867fe88df2f     Pulmonologist  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load dataset\n",
    "        df = pd.read_csv(dataset_path)\n",
    "\n",
    "        # Convert specified columns to fixed-length strings and flatten\n",
    "        train = np.array(df[[\"condition\"]].values, dtype=\"U10\").flatten()\n",
    "        train_labels = np.array(df[[\"SPECIALTY\"]].values, dtype=\"U10\").flatten()\n",
    "\n",
    "        # Split into train and test\n",
    "        self.train, self.test, self.train_labels, self.test_labels = sklearn.model_selection.train_test_split(\n",
    "            train, train_labels, test_size=0.20\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return raw strings for samples and labels\n",
    "        return self.train[idx], self.train_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MakeDatasetLoader(torch.utils.data.Dataset):\n",
    "#     def __init__(self, samples, labels, non_trainable_model):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.samples = samples\n",
    "#         self.labels = labels\n",
    "#         # self.samples = torch.from_numpy(samples.astype(np.float32)).to(device=torch.device(\"cpu\"), dtype=torch.float32)\n",
    "#         # self.labels = torch.from_numpy(labels.astype(np.float32)).to(device=torch.device(\"cpu\"), dtype=torch.float32)\n",
    "\n",
    "#         # print(samples[0])\n",
    "\n",
    "#         # self.labels = np.array(labels).tobytes()\n",
    "#         # self.samples = np.array(samples).tobytes()\n",
    "#         # print(labels)\n",
    "\n",
    "#         # Store the labels as tensors\n",
    "#         # self.labels = torch.tensor(labels, dtype=torch.float32).to(torch.device(\"cpu\"))\n",
    "        \n",
    "#         # Convert each sample into embeddings using the non_trainable_model\n",
    "#         # Assuming `samples` is a 1-column dataframe with text in each row\n",
    "#         # self.samples = [non_trainable_model.encode(sample[0], convert_to_tensor=True).to(torch.device(\"cpu\")) for sample in samples.values]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.samples)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.samples[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_trainable_model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_collate_fn(batch):\n",
    "#     # Separate samples and labels\n",
    "#     samples, labels = zip(*batch)\n",
    "    \n",
    "#     # Convert samples to embeddings\n",
    "#     sample_embeddings = [non_trainable_model.encode(sample, convert_to_tensor=True) for sample in samples]\n",
    "#     sample_embeddings = torch.stack(sample_embeddings)  # Stack embeddings into a single tensor\n",
    "    \n",
    "#     return sample_embeddings, list(labels)  # Return embeddings and raw labels\n",
    "\n",
    "\n",
    "# dataset = CustomDataset(dataset_path = path_patient_data_csv)\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.str_('Normal pre'), np.str_('Obstetrici'))\n",
      "[np.str_('Normal pre'), np.str_('Acute bron'), np.str_('Escherichi'), np.str_('Body mass '), np.str_('Anemia (di'), np.str_('Prediabete'), np.str_('Chronic pa'), np.str_('Acute vira'), np.str_('Malignant '), np.str_('Concussion'), np.str_('Stroke'), np.str_('Acute vira'), np.str_('Perennial '), np.str_('Acute bron'), np.str_('Fracture o'), np.str_('Viral sinu'), np.str_('Familial A'), np.str_('Viral sinu'), np.str_('Tubal preg'), np.str_('Viral sinu'), np.str_('Sprain of '), np.str_('Idiopathic'), np.str_('Viral sinu'), np.str_('Osteoarthr'), np.str_('Viral sinu'), np.str_('Drug overd'), np.str_('Non-small '), np.str_('Viral sinu'), np.str_('Anemia (di'), np.str_('Laceration'), np.str_('Fetus with'), np.str_('Prediabete')]\n",
      "[np.str_('Obstetrici'), np.str_('Pulmonolog'), np.str_('Urologist'), np.str_('Endocrinol'), np.str_('Hematologi'), np.str_('Endocrinol'), np.str_('Pain Manag'), np.str_('Otolaryngo'), np.str_('Oncologist'), np.str_('Neurologis'), np.str_('Neurologis'), np.str_('Otolaryngo'), np.str_('Allergist'), np.str_('Pulmonolog'), np.str_('Orthopedic'), np.str_('Otolaryngo'), np.str_('Neurologis'), np.str_('Otolaryngo'), np.str_('Obstetrici'), np.str_('Otolaryngo'), np.str_('Orthopedic'), np.str_('Endocrinol'), np.str_('Otolaryngo'), np.str_('Orthopedic'), np.str_('Otolaryngo'), np.str_('Toxicologi'), np.str_('Oncologist'), np.str_('Otolaryngo'), np.str_('Hematologi'), np.str_('General Su'), np.str_('Obstetrici'), np.str_('Endocrinol')]\n"
     ]
    }
   ],
   "source": [
    "# Define a custom collate function\n",
    "def collate_fn(batch):\n",
    "    # batch is a list of tuples (data, label)\n",
    "    data, labels = zip(*batch)\n",
    "    # Convert tuples to lists\n",
    "    data = list(data)\n",
    "    labels = list(labels)\n",
    "    return data, labels\n",
    "\n",
    "# Create an instance of your dataset\n",
    "dataset = CustomDataset(path_patient_data_csv)\n",
    "\n",
    "# Create a DataLoader with the custom collate function\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,        # Adjust batch_size as needed\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(dataset.__getitem__(0))\n",
    "\n",
    "# Now you can iterate over the DataLoader\n",
    "for batch_data, batch_labels in dataloader:\n",
    "    print(batch_data)    # List of strings (conditions)\n",
    "    print(batch_labels)  # List of strings (specialties)\n",
    "    break\n",
    "    # You can now process the batch_data and batch_labels as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_data = MakeDatasetLoader(train_samples, train_labels, non_trainable_model = non_trainable_model)\n",
    "# test_data = MakeDatasetLoader(test_samples, test_labels, non_trainable_model = non_trainable_model)\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(dataset=train_data, shuffle = True,batch_size = 2, collate_fn = custom_collate_fn)\n",
    "# test_dataloader = torch.utils.data.DataLoader(dataset=test_data, shuffle = False,batch_size = 2, collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# query = \"Hello I am Ovidiu\"\n",
    "\n",
    "# query_emb = model.encode(query)\n",
    "\n",
    "# print(query_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class SentenceTransformerWithHead(torch.nn.Module):\n",
    "    def __init__(self, curr_device=torch.device(\"cpu\")):\n",
    "        super(SentenceTransformerWithHead, self).__init__()\n",
    "        \n",
    "        # Load the pretrained sentence transformer\n",
    "        self.sentence_transformer = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "        \n",
    "        self.head = torch.nn.Linear(768, 768)  # Adjust size if model’s output size is different\n",
    "\n",
    "        self.device = curr_device\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def forward(self, input_text):\n",
    "        # input_text is a list of strings\n",
    "        # Obtain embeddings without computing gradients for the embedding model\n",
    "        embeddings = self.sentence_transformer.encode(\n",
    "            input_text,\n",
    "            convert_to_tensor=True,\n",
    "            device=self.device\n",
    "        )\n",
    "        # embeddings is a tensor on the correct device with requires_grad=False\n",
    "        \n",
    "        # Pass embeddings through the head\n",
    "        output = self.head(embeddings)\n",
    "        return output\n",
    "\n",
    "# Checkpoint Saving Function\n",
    "def save_checkpoint(epoch, model_trainable, optimizer, loss, checkpoint_path):\n",
    "    os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "    # Save model and optimizer state dictionaries, epoch, and loss\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_trainable.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "# Training Function\n",
    "def train_SentenceWithHead(model_non_trainable, model_trainable, dataloader, num_epochs=5, learning_rate=0.001, checkpoint_dir=\"./checkpoint\", device=torch.device(\"cpu\")):\n",
    "    optimizer = torch.optim.Adam(model_trainable.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.MSELoss()  # Mean Squared Error for Euclidean distance\n",
    "\n",
    "    model_trainable.to(device)\n",
    "    model_non_trainable.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model_trainable.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        with tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as tepoch:\n",
    "            for samples, labels in tepoch:\n",
    "                # Ensure samples and labels are lists of strings\n",
    "                samples = [str(sample) for sample in samples]\n",
    "                labels = [str(label) for label in labels]\n",
    "\n",
    "                # Move data to device (not necessary for strings)\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # samples = np.array(samples, dtype = np.str_)\n",
    "                # print(samples)\n",
    "                # print(samples.shape)\n",
    "\n",
    "                # Forward pass through the trainable model\n",
    "                outputs = model_trainable(samples)  # Outputs shape: [batch_size, embedding_dim]\n",
    "\n",
    "                # Generate target embeddings using the non-trainable model for labels\n",
    "                with torch.no_grad():\n",
    "                    target_embeddings = model_non_trainable.encode(labels)  # Shape: [batch_size, embedding_dim]\n",
    "                    target_embeddings = torch.tensor(target_embeddings).to(device)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, target_embeddings)\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "        # Save checkpoint at the end of each epoch\n",
    "        # checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch + 1}.pth\")\n",
    "        # save_checkpoint(epoch + 1, model_trainable, optimizer, avg_loss, checkpoint_path)\n",
    "    \n",
    "    torch.save(model_trainable.state_dict(), \"./model-saves/trainable_state_dict.pth\")\n",
    "    model_non_trainable.save(\"./model-saves/non_trainable_model\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<h2>Train<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 210/210 [00:19<00:00, 10.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.00544450869825336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 210/210 [00:19<00:00, 10.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.0011862881670822389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 210/210 [00:18<00:00, 11.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.0009890937444911937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 210/210 [00:19<00:00, 11.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.0009526315573090133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 210/210 [00:19<00:00, 10.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.0009496307073623895\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainable_model = SentenceTransformerWithHead(torch.device(\"mps\"))\n",
    "train_SentenceWithHead(model_non_trainable = non_trainable_model, model_trainable = trainable_model, dataloader = dataloader, checkpoint_dir = \"./checkpoint\", device = torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_unique_doctors = pd.read_csv(\"./unique_specialty.csv\")\n",
    "\n",
    "specialty_unique_doctors.head()\n",
    "\n",
    "specialty_unique = np.array(specialty_unique_doctors[\"SPECIALTY\"].values, dtype=\"U10\").flatten()\n",
    "specialty_unique = [str(sp) for sp in specialty_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(text, device, k):\n",
    "\n",
    "    non_trainable_model.eval()\n",
    "    non_trainable_model.to(device)\n",
    "\n",
    "    \n",
    "\n",
    "    # Compute embeddings for all specialties/doctors\n",
    "    with torch.no_grad():\n",
    "        doctor_embeddings = non_trainable_model.encode(specialty_unique)  # Shape: [num_doctors, embedding_dim]\n",
    "        doctor_embeddings = torch.tensor(doctor_embeddings).to(device)\n",
    "\n",
    "\n",
    "    trainable_model.eval()\n",
    "    trainable_model.to(device)\n",
    "    \n",
    "    # Compute the embedding for the input text\n",
    "    with torch.no_grad():\n",
    "        text_embedding = trainable_model([text])  # Shape: [1, embedding_dim]\n",
    "        text_embedding = torch.tensor(text_embedding).to(device)\n",
    "    \n",
    "\n",
    "    # Calculate the differences and compute the norms\n",
    "    distances = torch.norm(doctor_embeddings - text_embedding, dim=1)  # Shape: [num_doctors]\n",
    "    \n",
    "    # Find the indices of the k smallest distances\n",
    "    nearest_indices = torch.topk(distances, k, largest=False).indices\n",
    "    nearest_distances = distances[nearest_indices]\n",
    "    \n",
    "    # Retrieve the corresponding doctors/specialties\n",
    "    nearest_doctors = [specialty_unique[i] for i in nearest_indices.cpu().numpy()]\n",
    "\n",
    "    return list(zip(nearest_doctors, nearest_distances.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest doctors/specialties:\n",
      "AUDIOLOGIS: 5.4151930809021\n",
      "OTOLARYNGO: 6.006369113922119\n",
      "NEPHROLOGY: 6.435783863067627\n",
      "CARDIOVASC: 6.480925559997559\n",
      "GYNECOLOGI: 6.584884166717529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4b/dtlcb91s7yg2kmhy_wgzl_180000gn/T/ipykernel_54072/2552759417.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embedding = torch.tensor(text_embedding).to(device)\n"
     ]
    }
   ],
   "source": [
    "query = \"Acute bronchitis (disorder)\"\n",
    "\n",
    "nearest_doctors = knn(text = query, device = torch.device(\"mps\"), k = 5)\n",
    "\n",
    "# Print the results\n",
    "print(\"Nearest doctors/specialties:\")\n",
    "for doctor, distance in nearest_doctors:\n",
    "    print(f\"{doctor}: {distance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
